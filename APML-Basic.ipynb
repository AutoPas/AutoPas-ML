{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81542, 539)\n"
     ]
    }
   ],
   "source": [
    "# Load Data \n",
    "filename = 'C:\\\\Users\\\\deniz\\\\Desktop\\\\Thesis of ML for AutoPas\\\\Data\\\\Batch5\\\\final6.txt'\n",
    "arr = np.genfromtxt(filename, delimiter=',')\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model with 4 paramters\n",
    "parameter_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.5        0.078125   0.085184  ]\n",
      " [1.         0.75       0.015625   0.085184  ]\n",
      " [1.         1.         0.0625     0.074088  ]\n",
      " [1.         0.25       0.03125    0.039304  ]\n",
      " [1.         0.25       0.046875   0.054872  ]\n",
      " [0.66666667 0.25       0.046875   0.074088  ]\n",
      " [0.66666667 0.75       0.03125    0.216     ]\n",
      " [0.33333333 0.75       0.0625     0.013824  ]\n",
      " [0.33333333 0.75       0.125      0.884736  ]\n",
      " [0.33333333 1.         0.0625     0.175616  ]]\n"
     ]
    }
   ],
   "source": [
    "# Note, make sure the order of \n",
    "data = np.copy(arr)\n",
    "\n",
    "# Shuffle data and take 50% as test data\n",
    "np.random.shuffle(data)\n",
    "test_size = (np.ceil(data.shape[0] / 2)).astype(int)\n",
    "train_params = data[test_size:,0:parameter_count]\n",
    "train_labels = np.argmin(data[test_size:,-23:], 1).astype(int)\n",
    "test_params = data[:test_size,0:parameter_count]\n",
    "test_labels = np.argmin(data[:test_size,-23:], 1).astype(int)\n",
    "\n",
    "\n",
    "# Posible normalization functions\n",
    "def normalize01(array):\n",
    "    divisor = np.max(array)\n",
    "    for i in range(array.size):\n",
    "        array[i] = array[i] / divisor\n",
    "        \n",
    "np.apply_along_axis(normalize01, 0, train_params)\n",
    "np.apply_along_axis(normalize01, 0, test_params)\n",
    "print(train_params[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4066  2771  4742  4312 34431     0     0   652    13    28    16   255\n",
      "  1065   411     0    34    10    77     1    33 24520  3218   887]\n",
      "4\n",
      "0.42224865713374704\n"
     ]
    }
   ],
   "source": [
    "# Check how the total data is distributed among the labels\n",
    "dist = np.bincount(np.concatenate((train_labels, test_labels)))\n",
    "print(dist)\n",
    "print(np.argmax(dist))\n",
    "print(np.max(dist) / data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\deniz\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = keras.Sequential([\n",
    "    #keras.layers.Dense(parameter_count, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(4,)),\n",
    "    keras.layers.Dense(23, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40771/40771 [==============================] - 4s 93us/sample - loss: 1.5098 - acc: 0.5826\n",
      "Epoch 2/50\n",
      "40771/40771 [==============================] - 3s 64us/sample - loss: 1.0310 - acc: 0.7098\n",
      "Epoch 3/50\n",
      "40771/40771 [==============================] - 3s 64us/sample - loss: 0.9276 - acc: 0.7219\n",
      "Epoch 4/50\n",
      "40771/40771 [==============================] - 3s 65us/sample - loss: 0.8794 - acc: 0.7262\n",
      "Epoch 5/50\n",
      "40771/40771 [==============================] - 3s 75us/sample - loss: 0.8511 - acc: 0.7285\n",
      "Epoch 6/50\n",
      "40771/40771 [==============================] - 3s 66us/sample - loss: 0.8319 - acc: 0.7303\n",
      "Epoch 7/50\n",
      "40771/40771 [==============================] - 3s 69us/sample - loss: 0.8182 - acc: 0.7323\n",
      "Epoch 8/50\n",
      "40771/40771 [==============================] - 3s 70us/sample - loss: 0.8071 - acc: 0.7334\n",
      "Epoch 9/50\n",
      "40771/40771 [==============================] - 3s 70us/sample - loss: 0.7980 - acc: 0.7355\n",
      "Epoch 10/50\n",
      "40771/40771 [==============================] - 3s 74us/sample - loss: 0.7907 - acc: 0.7371\n",
      "Epoch 11/50\n",
      "40771/40771 [==============================] - 3s 70us/sample - loss: 0.7837 - acc: 0.7376\n",
      "Epoch 12/50\n",
      "40771/40771 [==============================] - 3s 67us/sample - loss: 0.7775 - acc: 0.7398\n",
      "Epoch 13/50\n",
      "40771/40771 [==============================] - 3s 68us/sample - loss: 0.7721 - acc: 0.7421\n",
      "Epoch 14/50\n",
      "40771/40771 [==============================] - 3s 64us/sample - loss: 0.7674 - acc: 0.7432\n",
      "Epoch 15/50\n",
      "40771/40771 [==============================] - 3s 71us/sample - loss: 0.7627 - acc: 0.7438\n",
      "Epoch 16/50\n",
      "40771/40771 [==============================] - 3s 86us/sample - loss: 0.7578 - acc: 0.7454\n",
      "Epoch 17/50\n",
      "40771/40771 [==============================] - 3s 73us/sample - loss: 0.7542 - acc: 0.7461\n",
      "Epoch 18/50\n",
      "40771/40771 [==============================] - 3s 85us/sample - loss: 0.7505 - acc: 0.7470\n",
      "Epoch 19/50\n",
      "40771/40771 [==============================] - 3s 67us/sample - loss: 0.7473 - acc: 0.7471\n",
      "Epoch 20/50\n",
      "40771/40771 [==============================] - 3s 73us/sample - loss: 0.7439 - acc: 0.7481\n",
      "Epoch 21/50\n",
      "40771/40771 [==============================] - 3s 78us/sample - loss: 0.7415 - acc: 0.7494\n",
      "Epoch 22/50\n",
      "40771/40771 [==============================] - 3s 68us/sample - loss: 0.7385 - acc: 0.7505\n",
      "Epoch 23/50\n",
      "40771/40771 [==============================] - 3s 82us/sample - loss: 0.7362 - acc: 0.7497\n",
      "Epoch 24/50\n",
      "40771/40771 [==============================] - 3s 73us/sample - loss: 0.7342 - acc: 0.7506\n",
      "Epoch 25/50\n",
      "40771/40771 [==============================] - 3s 77us/sample - loss: 0.7319 - acc: 0.7517\n",
      "Epoch 26/50\n",
      "40771/40771 [==============================] - 3s 79us/sample - loss: 0.7302 - acc: 0.7522\n",
      "Epoch 27/50\n",
      "40771/40771 [==============================] - 3s 78us/sample - loss: 0.7283 - acc: 0.7528\n",
      "Epoch 28/50\n",
      "40771/40771 [==============================] - 3s 80us/sample - loss: 0.7270 - acc: 0.7522\n",
      "Epoch 29/50\n",
      "40771/40771 [==============================] - 3s 68us/sample - loss: 0.7253 - acc: 0.7522\n",
      "Epoch 30/50\n",
      "40771/40771 [==============================] - 3s 83us/sample - loss: 0.7238 - acc: 0.7531\n",
      "Epoch 31/50\n",
      "40771/40771 [==============================] - 3s 77us/sample - loss: 0.7220 - acc: 0.7529\n",
      "Epoch 32/50\n",
      "40771/40771 [==============================] - 3s 69us/sample - loss: 0.7212 - acc: 0.7534\n",
      "Epoch 33/50\n",
      "40771/40771 [==============================] - 3s 71us/sample - loss: 0.7200 - acc: 0.7536\n",
      "Epoch 34/50\n",
      "40771/40771 [==============================] - 3s 70us/sample - loss: 0.7182 - acc: 0.7547\n",
      "Epoch 35/50\n",
      "40771/40771 [==============================] - 3s 70us/sample - loss: 0.7175 - acc: 0.7541\n",
      "Epoch 36/50\n",
      "40771/40771 [==============================] - 3s 71us/sample - loss: 0.7164 - acc: 0.7550\n",
      "Epoch 37/50\n",
      "40771/40771 [==============================] - 3s 81us/sample - loss: 0.7147 - acc: 0.7556\n",
      "Epoch 38/50\n",
      "40771/40771 [==============================] - 3s 72us/sample - loss: 0.7146 - acc: 0.7559\n",
      "Epoch 39/50\n",
      "40771/40771 [==============================] - 3s 71us/sample - loss: 0.7130 - acc: 0.7564\n",
      "Epoch 40/50\n",
      "40771/40771 [==============================] - 3s 73us/sample - loss: 0.7123 - acc: 0.7573\n",
      "Epoch 41/50\n",
      "40771/40771 [==============================] - 3s 73us/sample - loss: 0.7112 - acc: 0.7568\n",
      "Epoch 42/50\n",
      "40771/40771 [==============================] - 3s 79us/sample - loss: 0.7103 - acc: 0.7583\n",
      "Epoch 43/50\n",
      "40771/40771 [==============================] - 3s 70us/sample - loss: 0.7096 - acc: 0.7578\n",
      "Epoch 44/50\n",
      "40771/40771 [==============================] - 3s 75us/sample - loss: 0.7086 - acc: 0.7582\n",
      "Epoch 45/50\n",
      "40771/40771 [==============================] - 3s 75us/sample - loss: 0.7078 - acc: 0.7585\n",
      "Epoch 46/50\n",
      "40771/40771 [==============================] - 3s 74us/sample - loss: 0.7070 - acc: 0.7586\n",
      "Epoch 47/50\n",
      "40771/40771 [==============================] - 3s 77us/sample - loss: 0.7062 - acc: 0.7585\n",
      "Epoch 48/50\n",
      "40771/40771 [==============================] - 3s 78us/sample - loss: 0.7054 - acc: 0.7598\n",
      "Epoch 49/50\n",
      "40771/40771 [==============================] - 3s 75us/sample - loss: 0.7045 - acc: 0.7602\n",
      "Epoch 50/50\n",
      "40771/40771 [==============================] - 3s 71us/sample - loss: 0.7038 - acc: 0.7598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22db0be7940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fun\n",
    "model.fit(train_params, train_labels , epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40771/40771 [==============================] - 2s 46us/sample - loss: 0.7009 - acc: 0.7599\n",
      "Test accuracy: 0.75987834\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_params)\n",
    "test_loss, test_acc = model.evaluate(test_params, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best  Guess1  Guess2  Certainty1      Certainty2\n",
      "  4 \t 4 \t 3 \t 72.45% \t 22.82%\n",
      "  1 \t 2 \t 1 \t 38.63% \t 37.39%\n",
      "  0 \t 0 \t 20 \t 56.01% \t 39.20%\n",
      "  1 \t 2 \t 20 \t 50.39% \t 13.01%\n",
      "  21 \t 4 \t 3 \t 36.98% \t 32.65%\n",
      "  2 \t 20 \t 2 \t 62.45% \t 10.52%\n",
      "  1 \t 20 \t 0 \t 33.27% \t 27.48%\n",
      "  4 \t 4 \t 3 \t 87.77% \t 12.15%\n",
      "  4 \t 4 \t 3 \t 99.25% \t 0.38%\n",
      "  3 \t 3 \t 4 \t 47.09% \t 37.13%\n",
      "  4 \t 4 \t 1 \t 98.75% \t 0.74%\n",
      "  4 \t 4 \t 1 \t 98.89% \t 0.58%\n",
      "  4 \t 4 \t 3 \t 98.62% \t 0.73%\n",
      "  0 \t 20 \t 0 \t 77.48% \t 17.08%\n",
      "  20 \t 20 \t 0 \t 74.29% \t 8.80%\n",
      "  1 \t 2 \t 20 \t 37.18% \t 20.67%\n",
      "  4 \t 4 \t 3 \t 90.92% \t 9.08%\n",
      "  4 \t 4 \t 3 \t 88.32% \t 11.66%\n",
      "  20 \t 20 \t 0 \t 90.93% \t 3.69%\n",
      "  4 \t 4 \t 3 \t 88.96% \t 10.80%\n"
     ]
    }
   ],
   "source": [
    "# Print prediction, result, and how certain the result is\n",
    "best = np.argsort(predictions)\n",
    "print(' Best  Guess1  Guess2  Certainty1      Certainty2')\n",
    "for i in range(20):\n",
    "    print(' ', test_labels[i], '\\t', best[i][-1], '\\t', best[i][-2], '\\t', \\\n",
    "          \"{:.2%}\".format(predictions[i][best[i][-1]]), '\\t', \"{:.2%}\".format(predictions[i][best[i][-2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of guesses until correct choice: [30981  5486  2516   715   444   324   183    47    19    31    19     4\n",
      "     1     0     0     0     1     0     0     0     0     0     0]\n",
      "Cumilative chance that the choice was correct by: [0.76  0.894 0.956 0.974 0.985]\n",
      "The count of most occuring tests: [17246 12259  2374  2174  2038  1612  1388   509   427   317   205   120\n",
      "    38    15    14    12     9     7     6     1     0     0     0]\n",
      "Cumilative chance that the choice was correct by: [0.423 0.724 0.782 0.835 0.885]\n"
     ]
    }
   ],
   "source": [
    "# Print general statistics about in how many guesses the AI would be correct\n",
    "correct = np.zeros(best.shape[1])\n",
    "most_occuring = np.sort(np.bincount(test_labels))[::-1]\n",
    "for i in range(test_size):\n",
    "    for j in range(correct.size):\n",
    "        if best[i][-j-1] == test_labels[i]:\n",
    "            correct[j] = correct[j] + 1\n",
    "            break\n",
    "np.set_printoptions(precision=3)\n",
    "print('The count of guesses until correct choice:', correct.astype(int))\n",
    "print('Cumilative chance that the choice was correct by:', \\\n",
    "      np.apply_along_axis(lambda x: x / test_size, 0, np.cumsum(correct))[0:5])\n",
    "print('The count of most occuring tests:', most_occuring)\n",
    "print('Cumilative chance that the choice was correct by:', \\\n",
    "      np.apply_along_axis(lambda x: x / test_size, 0, np.cumsum(most_occuring))[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deniz\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "C:\\Users\\deniz\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "The average: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10996 second best results from 81542 are within 1 percent speed difference\n",
      "24714 non best results from 81542 are within 1 percent speed difference\n",
      "19060 second best results from 81542 are within 5 percent speed difference\n"
     ]
    }
   ],
   "source": [
    "# Display relative timing of all experiments, and print the ones which are relatively close\n",
    "timings = np.apply_along_axis(lambda x: np.sort(x), 1, arr[:, parameter_count:])\n",
    "for i in range(timings.shape[0]):\n",
    "    fastest = timings[i][0]\n",
    "    for j in range(timings.shape[1]):\n",
    "        timings[i][j] = timings[i][j] / fastest\n",
    "\n",
    "for i in range(3):\n",
    "    print(timings[i])\n",
    "    \n",
    "print('The average:', np.average(timings, 0))\n",
    "\n",
    "count = 0\n",
    "for i in range(timings.shape[0]):\n",
    "    if timings[i][1] < 1.01:\n",
    "        count = count + 1\n",
    "print(count, 'second best results from', timings.shape[0], 'are within 1 percent speed difference')\n",
    "\n",
    "count = 0\n",
    "for i in range(timings.shape[0]):\n",
    "    for j in range(1, timings.shape[1]):\n",
    "        if timings[i][j] < 1.01:\n",
    "            count = count + 1\n",
    "print(count, 'non best results from', timings.shape[0], 'are within 1 percent speed difference')\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(timings.shape[0]):\n",
    "    if timings[i][1] < 1.05:\n",
    "        count = count + 1\n",
    "print(count, 'second best results from', timings.shape[0], 'are within 5 percent speed difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deniz\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n",
      "C:\\Users\\deniz\\Anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 first guesses from 40771 are within 1 percent speed difference\n",
      "130 first guesses from 40771 are within 5 percent speed difference\n",
      "1068 of first two guesses from 40771 are within 1 percent speed difference\n"
     ]
    }
   ],
   "source": [
    "# Count the first guesses that were relatively quick\n",
    "test_timings = data[:test_size,parameter_count:]\n",
    "for i in range(test_timings.shape[0]):\n",
    "    fastest = np.min(test_timings[i])\n",
    "    for j in range(test_timings.shape[1]):\n",
    "        test_timings[i][j] = test_timings[i][j] / fastest\n",
    "        \n",
    "count = 0\n",
    "for i in range(test_size):\n",
    "    if test_timings[i][best[i][-1]] < 1.01:\n",
    "        count = count + 1\n",
    "print(count, 'first guesses from', test_size, 'are within 1 percent speed difference')\n",
    "\n",
    "count = 0\n",
    "for i in range(test_size):\n",
    "    if test_timings[i][best[i][-1]] < 1.05:\n",
    "        count = count + 1\n",
    "print(count, 'first guesses from', test_size, 'are within 5 percent speed difference')\n",
    "\n",
    "count = 0\n",
    "for i in range(test_size):\n",
    "    if test_timings[i][best[i][-1]] < 1.01 or test_timings[i][best[i][-2]] < 1.01:\n",
    "        count = count + 1\n",
    "print(count, 'of first two guesses from', test_size, 'are within 1 percent speed difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 23)                391       \n",
      "=================================================================\n",
      "Total params: 471\n",
      "Trainable params: 471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/deniz/Desktop/Thesis of ML for AutoPas/keras_model.h5', include_optimizer=False) #include_optimizer=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
