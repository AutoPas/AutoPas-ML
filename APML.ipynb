{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 30)\n"
     ]
    }
   ],
   "source": [
    "# Load Data \n",
    "filename = 'C:\\\\Users\\\\deniz\\\\Desktop\\\\Thesis of ML for AutoPas\\\\Data\\\\Batch3\\\\b3e1-6.txt'\n",
    "arr = np.genfromtxt(filename, delimiter=',')\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how many parameters you have (it is assumed that the rest are classes)\n",
    "parameter_count = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.44140625e-05 7.32421875e-04 0.00000000e+00 0.00000000e+00\n",
      " 2.44140625e-04 1.00000000e+00 3.70371094e-02]\n"
     ]
    }
   ],
   "source": [
    "# Copy the array\n",
    "data = arr\n",
    "\n",
    "# Shuffle data and take 80% as test data\n",
    "np.random.shuffle(data)\n",
    "test_size = (np.ceil(data.shape[0] * 4 / 5)).astype(int)\n",
    "train_params = data[test_size:,0:parameter_count]\n",
    "train_labels = np.argmin(data[test_size:,parameter_count:], 1).astype(int)\n",
    "test_params = data[:test_size,0:parameter_count]\n",
    "test_labels = np.argmin(data[:test_size,parameter_count:], 1).astype(int)\n",
    "\n",
    "\n",
    "# Posible normalization functions\n",
    "def normalize01(array):\n",
    "    divisor = np.max(array)\n",
    "    for i in range(array.size):\n",
    "        array[i] = array[i] / divisor\n",
    "        \n",
    "def normalize02(array):\n",
    "    divisor = np.max(array)\n",
    "    sub = np.min(array)\n",
    "    for i in range(array.size):\n",
    "        array[i] = (array[i] - sub) / divisor\n",
    "        \n",
    "# Normalize the data\n",
    "np.apply_along_axis(normalize02, 1, train_params)\n",
    "np.apply_along_axis(normalize02, 1, test_params)\n",
    "print(train_params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[281   9  54   0  33   0   0  43   0   0   0   0   5   3   0   0   0   1\n",
      "   0   0 409   0  40]\n",
      "20\n",
      "0.46583143507972663\n"
     ]
    }
   ],
   "source": [
    "# Check how the total data is distributed among the labels\n",
    "dist = np.bincount(np.concatenate((train_labels, test_labels)))\n",
    "print(dist)\n",
    "print(np.argmax(dist))\n",
    "print(np.max(dist) / data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = keras.Sequential([\n",
    "    #keras.layers.Dense(parameter_count, activation=tf.nn.relu, input_dim=7),\n",
    "    keras.layers.Dense(parameter_count, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(arr.shape[1] - parameter_count, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.25)\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(arr.shape[1] - parameter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\deniz\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 3ms/sample - loss: 1.9473 - acc: 0.2743\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.4983 - acc: 0.4343\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.4041 - acc: 0.4343\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.4097 - acc: 0.3600\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.3599 - acc: 0.4343\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.3392 - acc: 0.4114\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.3195 - acc: 0.4514\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.3496 - acc: 0.3486\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.3274 - acc: 0.4743\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.3199 - acc: 0.3829\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2991 - acc: 0.4743\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 0s 109us/sample - loss: 1.2973 - acc: 0.4057\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.3030 - acc: 0.4229\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2790 - acc: 0.4171\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.2550 - acc: 0.4857\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.2614 - acc: 0.3600\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2668 - acc: 0.4743\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.2558 - acc: 0.4571\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 0s 108us/sample - loss: 1.2595 - acc: 0.4114\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2407 - acc: 0.4743\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2624 - acc: 0.4171\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.3030 - acc: 0.4229\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.2050 - acc: 0.4857\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 0s 114us/sample - loss: 1.2466 - acc: 0.4800\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2243 - acc: 0.5200\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2044 - acc: 0.4286\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.2036 - acc: 0.4343\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.1892 - acc: 0.4971\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 0s 109us/sample - loss: 1.2072 - acc: 0.4971\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 0s 166us/sample - loss: 1.1394 - acc: 0.5543\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.1769 - acc: 0.5143\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.1666 - acc: 0.5143\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.1474 - acc: 0.5143\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 0s 86us/sample - loss: 1.2210 - acc: 0.4857\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 0s 86us/sample - loss: 1.2605 - acc: 0.4457\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 0s 86us/sample - loss: 1.1269 - acc: 0.4914\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.2949 - acc: 0.4686\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 0s 86us/sample - loss: 1.2836 - acc: 0.4514\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 0s 86us/sample - loss: 1.3014 - acc: 0.4857\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.2172 - acc: 0.5200\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 0s 86us/sample - loss: 1.1463 - acc: 0.5200\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 0s 120us/sample - loss: 1.1512 - acc: 0.5029\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.1012 - acc: 0.5429\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.1222 - acc: 0.5086\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 0s 103us/sample - loss: 1.0797 - acc: 0.5543\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 0s 91us/sample - loss: 1.0997 - acc: 0.5200\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 0s 126us/sample - loss: 1.1271 - acc: 0.5314\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 0s 97us/sample - loss: 1.0807 - acc: 0.5257\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 0s 131us/sample - loss: 1.0918 - acc: 0.4857\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - ETA: 0s - loss: 1.2264 - acc: 0.437 - 0s 91us/sample - loss: 1.0731 - acc: 0.4686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ead6fd400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fun\n",
    "model.fit(train_params, train_labels , epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 0s 175us/sample - loss: 1.0610 - acc: 0.5078\n",
      "Test accuracy: 0.5078236\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_params)\n",
    "test_loss, test_acc = model.evaluate(test_params, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best  Guess1  Guess2  Certainty1      Certainty2\n",
      "  0 \t 20 \t 0 \t 48.67% \t 47.93%\n",
      "  20 \t 20 \t 2 \t 44.23% \t 18.07%\n",
      "  20 \t 20 \t 0 \t 49.35% \t 15.56%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 47.94%\n",
      "  20 \t 20 \t 0 \t 48.48% \t 48.13%\n",
      "  0 \t 0 \t 20 \t 48.21% \t 46.82%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.22%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  20 \t 20 \t 2 \t 44.52% \t 17.82%\n",
      "  2 \t 20 \t 2 \t 43.78% \t 18.44%\n",
      "  20 \t 20 \t 0 \t 53.60% \t 19.41%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  20 \t 20 \t 0 \t 48.70% \t 47.90%\n",
      "  0 \t 20 \t 0 \t 48.74% \t 47.86%\n",
      "  20 \t 20 \t 2 \t 47.34% \t 15.51%\n",
      "  20 \t 20 \t 2 \t 44.54% \t 17.80%\n",
      "  0 \t 20 \t 0 \t 55.25% \t 21.73%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.90%\n",
      "  7 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 49.86% \t 15.98%\n",
      "  0 \t 0 \t 20 \t 48.12% \t 46.51%\n",
      "  1 \t 20 \t 2 \t 43.46% \t 18.69%\n",
      "  20 \t 20 \t 2 \t 44.66% \t 17.70%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.88%\n",
      "  20 \t 20 \t 0 \t 48.57% \t 48.03%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 20 \t 0 \t 48.59% \t 48.03%\n",
      "  20 \t 20 \t 0 \t 53.11% \t 18.83%\n",
      "  0 \t 20 \t 0 \t 53.25% \t 19.02%\n",
      "  0 \t 20 \t 0 \t 48.65% \t 47.96%\n",
      "  20 \t 20 \t 0 \t 50.06% \t 16.15%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 47.79%\n",
      "  0 \t 20 \t 0 \t 48.77% \t 47.84%\n",
      "  20 \t 20 \t 0 \t 53.25% \t 19.00%\n",
      "  0 \t 20 \t 0 \t 57.53% \t 26.70%\n",
      "  0 \t 20 \t 0 \t 48.69% \t 47.92%\n",
      "  2 \t 20 \t 2 \t 43.06% \t 19.02%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 2 \t 44.97% \t 17.43%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.91%\n",
      "  0 \t 20 \t 0 \t 48.51% \t 48.13%\n",
      "  20 \t 20 \t 0 \t 53.08% \t 18.80%\n",
      "  20 \t 20 \t 2 \t 46.98% \t 15.83%\n",
      "  20 \t 20 \t 0 \t 53.39% \t 19.16%\n",
      "  20 \t 0 \t 20 \t 48.18% \t 46.71%\n",
      "  0 \t 20 \t 0 \t 53.14% \t 18.88%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 47.77%\n",
      "  0 \t 0 \t 20 \t 48.11% \t 46.49%\n",
      "  20 \t 20 \t 2 \t 44.37% \t 17.95%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.94%\n",
      "  20 \t 0 \t 20 \t 48.16% \t 46.66%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.89%\n",
      "  20 \t 20 \t 2 \t 45.41% \t 17.06%\n",
      "  20 \t 20 \t 0 \t 48.49% \t 48.13%\n",
      "  0 \t 0 \t 20 \t 48.18% \t 46.73%\n",
      "  0 \t 20 \t 0 \t 53.17% \t 18.92%\n",
      "  4 \t 20 \t 2 \t 45.96% \t 16.64%\n",
      "  20 \t 20 \t 2 \t 44.49% \t 17.84%\n",
      "  0 \t 0 \t 20 \t 48.21% \t 46.83%\n",
      "  0 \t 20 \t 0 \t 48.68% \t 47.93%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.05%\n",
      "  0 \t 20 \t 0 \t 57.54% \t 26.88%\n",
      "  20 \t 20 \t 2 \t 44.82% \t 17.56%\n",
      "  20 \t 20 \t 0 \t 53.15% \t 18.88%\n",
      "  20 \t 20 \t 0 \t 53.16% \t 18.89%\n",
      "  20 \t 20 \t 0 \t 53.44% \t 19.25%\n",
      "  0 \t 20 \t 0 \t 48.32% \t 48.32%\n",
      "  2 \t 20 \t 2 \t 45.78% \t 16.81%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.89%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.08%\n",
      "  1 \t 20 \t 2 \t 44.21% \t 18.09%\n",
      "  2 \t 20 \t 2 \t 43.44% \t 18.71%\n",
      "  20 \t 0 \t 20 \t 48.14% \t 46.59%\n",
      "  2 \t 20 \t 2 \t 44.83% \t 17.58%\n",
      "  20 \t 20 \t 0 \t 53.20% \t 18.94%\n",
      "  20 \t 20 \t 0 \t 57.61% \t 28.39%\n",
      "  4 \t 20 \t 2 \t 45.25% \t 17.24%\n",
      "  7 \t 20 \t 2 \t 43.09% \t 19.00%\n",
      "  0 \t 20 \t 2 \t 46.96% \t 15.85%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.87%\n",
      "  7 \t 20 \t 2 \t 44.11% \t 18.17%\n",
      "  0 \t 20 \t 0 \t 48.71% \t 47.89%\n",
      "  7 \t 20 \t 2 \t 47.47% \t 15.41%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  20 \t 20 \t 0 \t 57.61% \t 28.15%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  0 \t 20 \t 0 \t 57.54% \t 26.85%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.20%\n",
      "  20 \t 20 \t 0 \t 48.63% \t 47.98%\n",
      "  0 \t 20 \t 0 \t 48.68% \t 47.93%\n",
      "  7 \t 20 \t 2 \t 44.89% \t 17.53%\n",
      "  20 \t 20 \t 0 \t 57.54% \t 26.82%\n",
      "  20 \t 20 \t 0 \t 54.24% \t 20.22%\n",
      "  0 \t 0 \t 20 \t 48.17% \t 46.69%\n",
      "  0 \t 20 \t 0 \t 48.55% \t 48.07%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.85%\n",
      "  4 \t 20 \t 2 \t 44.43% \t 17.91%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  1 \t 20 \t 2 \t 43.76% \t 18.45%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.86%\n",
      "  0 \t 0 \t 20 \t 48.00% \t 46.14%\n",
      "  20 \t 20 \t 0 \t 49.32% \t 15.54%\n",
      "  20 \t 20 \t 2 \t 45.48% \t 17.00%\n",
      "  0 \t 20 \t 0 \t 48.57% \t 48.04%\n",
      "  20 \t 20 \t 0 \t 57.53% \t 26.71%\n",
      "  7 \t 20 \t 2 \t 44.31% \t 18.00%\n",
      "  20 \t 20 \t 0 \t 53.17% \t 18.91%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.87%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.87%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  7 \t 20 \t 2 \t 44.22% \t 18.08%\n",
      "  7 \t 20 \t 2 \t 44.10% \t 18.18%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  20 \t 20 \t 0 \t 53.57% \t 19.42%\n",
      "  20 \t 20 \t 0 \t 53.13% \t 18.87%\n",
      "  7 \t 20 \t 2 \t 43.23% \t 18.88%\n",
      "  7 \t 20 \t 2 \t 43.08% \t 19.00%\n",
      "  20 \t 20 \t 0 \t 48.67% \t 47.94%\n",
      "  20 \t 20 \t 2 \t 44.13% \t 18.15%\n",
      "  0 \t 0 \t 20 \t 48.08% \t 46.38%\n",
      "  20 \t 20 \t 0 \t 48.59% \t 48.01%\n",
      "  20 \t 20 \t 0 \t 49.33% \t 15.54%\n",
      "  20 \t 20 \t 2 \t 44.16% \t 18.12%\n",
      "  20 \t 20 \t 0 \t 53.23% \t 18.99%\n",
      "  7 \t 20 \t 2 \t 43.24% \t 18.87%\n",
      "  20 \t 20 \t 0 \t 53.89% \t 19.81%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 20 \t 2 \t 46.97% \t 15.83%\n",
      "  20 \t 20 \t 0 \t 53.15% \t 18.89%\n",
      "  0 \t 20 \t 0 \t 48.74% \t 47.87%\n",
      "  20 \t 20 \t 0 \t 48.50% \t 48.12%\n",
      "  20 \t 20 \t 0 \t 54.39% \t 20.58%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.94%\n",
      "  0 \t 20 \t 0 \t 49.32% \t 15.54%\n",
      "  0 \t 20 \t 0 \t 48.74% \t 47.86%\n",
      "  20 \t 20 \t 0 \t 57.53% \t 26.73%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  20 \t 20 \t 0 \t 54.15% \t 20.23%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.20%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  20 \t 20 \t 0 \t 48.65% \t 47.95%\n",
      "  20 \t 20 \t 0 \t 49.83% \t 15.95%\n",
      "  1 \t 20 \t 2 \t 44.32% \t 18.00%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  2 \t 20 \t 2 \t 44.22% \t 18.08%\n",
      "  0 \t 20 \t 0 \t 53.29% \t 19.07%\n",
      "  0 \t 20 \t 0 \t 48.69% \t 47.92%\n",
      "  20 \t 20 \t 0 \t 53.69% \t 19.58%\n",
      "  0 \t 20 \t 0 \t 48.72% \t 47.89%\n",
      "  20 \t 20 \t 0 \t 57.60% \t 28.64%\n",
      "  0 \t 0 \t 20 \t 48.20% \t 46.79%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 48.56% \t 48.05%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.63%\n",
      "  20 \t 20 \t 2 \t 44.20% \t 18.09%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.31%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.62%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.94%\n",
      "  0 \t 20 \t 0 \t 48.64% \t 47.98%\n",
      "  0 \t 20 \t 0 \t 49.34% \t 15.56%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.15%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.87%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.91%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  7 \t 20 \t 2 \t 43.24% \t 18.88%\n",
      "  0 \t 20 \t 0 \t 48.62% \t 48.00%\n",
      "  7 \t 20 \t 2 \t 43.45% \t 18.70%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.29%\n",
      "  0 \t 20 \t 0 \t 53.28% \t 19.06%\n",
      "  0 \t 20 \t 0 \t 48.72% \t 47.88%\n",
      "  20 \t 20 \t 0 \t 54.81% \t 21.02%\n",
      "  2 \t 20 \t 2 \t 47.40% \t 15.47%\n",
      "  0 \t 20 \t 0 \t 57.60% \t 28.52%\n",
      "  0 \t 20 \t 0 \t 48.77% \t 47.84%\n",
      "  20 \t 0 \t 20 \t 47.77% \t 45.59%\n",
      "  20 \t 20 \t 0 \t 53.50% \t 19.28%\n",
      "  20 \t 20 \t 0 \t 53.20% \t 18.95%\n",
      "  0 \t 20 \t 0 \t 48.62% \t 47.99%\n",
      "  1 \t 20 \t 2 \t 43.76% \t 18.45%\n",
      "  20 \t 20 \t 0 \t 57.55% \t 26.90%\n",
      "  0 \t 20 \t 0 \t 48.65% \t 47.97%\n",
      "  4 \t 20 \t 2 \t 44.89% \t 17.53%\n",
      "  0 \t 20 \t 0 \t 57.56% \t 27.03%\n",
      "  20 \t 20 \t 0 \t 49.79% \t 15.92%\n",
      "  20 \t 20 \t 0 \t 53.20% \t 18.95%\n",
      "  2 \t 20 \t 2 \t 44.19% \t 18.10%\n",
      "  20 \t 20 \t 0 \t 48.70% \t 47.90%\n",
      "  2 \t 20 \t 2 \t 43.45% \t 18.70%\n",
      "  20 \t 20 \t 0 \t 55.49% \t 22.62%\n",
      "  20 \t 20 \t 2 \t 44.16% \t 18.12%\n",
      "  20 \t 0 \t 20 \t 48.19% \t 46.76%\n",
      "  7 \t 20 \t 2 \t 44.09% \t 18.19%\n",
      "  7 \t 20 \t 2 \t 45.89% \t 16.71%\n",
      "  2 \t 20 \t 2 \t 43.79% \t 18.43%\n",
      "  4 \t 20 \t 2 \t 44.79% \t 17.61%\n",
      "  20 \t 0 \t 20 \t 48.16% \t 46.65%\n",
      "  4 \t 20 \t 2 \t 45.55% \t 16.98%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.65%\n",
      "  0 \t 20 \t 0 \t 48.78% \t 47.82%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.94%\n",
      "  20 \t 20 \t 2 \t 44.28% \t 18.02%\n",
      "  0 \t 20 \t 0 \t 48.70% \t 47.90%\n",
      "  20 \t 0 \t 20 \t 48.20% \t 46.81%\n",
      "  20 \t 20 \t 2 \t 44.18% \t 18.11%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.26%\n",
      "  0 \t 0 \t 20 \t 48.11% \t 46.47%\n",
      "  20 \t 20 \t 0 \t 49.31% \t 15.53%\n",
      "  0 \t 20 \t 0 \t 48.35% \t 48.28%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.91%\n",
      "  20 \t 0 \t 20 \t 47.74% \t 45.52%\n",
      "  20 \t 20 \t 2 \t 44.57% \t 17.78%\n",
      "  2 \t 20 \t 2 \t 43.77% \t 18.44%\n",
      "  0 \t 20 \t 2 \t 46.96% \t 15.84%\n",
      "  2 \t 20 \t 2 \t 44.36% \t 17.96%\n",
      "  20 \t 20 \t 2 \t 44.60% \t 17.75%\n",
      "  20 \t 20 \t 2 \t 45.22% \t 17.22%\n",
      "  2 \t 20 \t 2 \t 44.81% \t 17.59%\n",
      "  12 \t 20 \t 2 \t 43.24% \t 18.87%\n",
      "  0 \t 0 \t 20 \t 48.17% \t 46.69%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.66%\n",
      "  2 \t 20 \t 2 \t 44.19% \t 18.11%\n",
      "  20 \t 20 \t 2 \t 44.29% \t 18.02%\n",
      "  20 \t 20 \t 0 \t 48.69% \t 47.92%\n",
      "  0 \t 0 \t 20 \t 48.20% \t 46.79%\n",
      "  20 \t 20 \t 0 \t 53.22% \t 18.97%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  2 \t 20 \t 2 \t 44.11% \t 18.17%\n",
      "  20 \t 0 \t 20 \t 48.18% \t 46.72%\n",
      "  0 \t 20 \t 0 \t 48.77% \t 47.83%\n",
      "  20 \t 20 \t 2 \t 44.17% \t 18.12%\n",
      "  0 \t 0 \t 20 \t 48.19% \t 46.76%\n",
      "  20 \t 20 \t 0 \t 48.47% \t 48.14%\n",
      "  1 \t 20 \t 2 \t 44.53% \t 17.83%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.85%\n",
      "  0 \t 20 \t 0 \t 48.58% \t 48.04%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.02%\n",
      "  20 \t 20 \t 0 \t 53.13% \t 18.87%\n",
      "  12 \t 20 \t 2 \t 44.20% \t 18.10%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.97%\n",
      "  20 \t 20 \t 0 \t 57.61% \t 28.05%\n",
      "  7 \t 20 \t 2 \t 43.07% \t 19.01%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.94%\n",
      "  0 \t 20 \t 0 \t 48.60% \t 48.03%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.02%\n",
      "  20 \t 0 \t 20 \t 48.01% \t 46.17%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.86%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  0 \t 20 \t 0 \t 49.31% \t 15.53%\n",
      "  7 \t 20 \t 2 \t 44.24% \t 18.06%\n",
      "  20 \t 20 \t 0 \t 53.45% \t 19.27%\n",
      "  0 \t 0 \t 20 \t 48.20% \t 46.80%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.94%\n",
      "  0 \t 20 \t 0 \t 48.70% \t 47.91%\n",
      "  20 \t 20 \t 0 \t 53.27% \t 19.04%\n",
      "  20 \t 20 \t 0 \t 53.34% \t 19.10%\n",
      "  20 \t 20 \t 0 \t 48.61% \t 48.00%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.13%\n",
      "  20 \t 20 \t 2 \t 45.35% \t 17.11%\n",
      "  20 \t 20 \t 0 \t 53.10% \t 18.82%\n",
      "  20 \t 20 \t 0 \t 53.10% \t 18.83%\n",
      "  20 \t 20 \t 0 \t 57.56% \t 26.99%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.30%\n",
      "  0 \t 20 \t 0 \t 48.74% \t 47.87%\n",
      "  0 \t 0 \t 20 \t 48.18% \t 46.70%\n",
      "  20 \t 20 \t 0 \t 48.64% \t 47.96%\n",
      "  20 \t 0 \t 20 \t 48.15% \t 46.60%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 20 \t 0 \t 53.38% \t 19.15%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.29%\n",
      "  2 \t 20 \t 2 \t 44.30% \t 18.02%\n",
      "  20 \t 0 \t 20 \t 48.20% \t 46.80%\n",
      "  2 \t 20 \t 2 \t 43.07% \t 19.01%\n",
      "  20 \t 20 \t 0 \t 53.21% \t 18.95%\n",
      "  20 \t 20 \t 0 \t 54.43% \t 20.64%\n",
      "  7 \t 20 \t 2 \t 44.14% \t 18.14%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  20 \t 20 \t 0 \t 48.40% \t 48.21%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.71% \t 19.61%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.24%\n",
      "  2 \t 20 \t 2 \t 43.08% \t 19.00%\n",
      "  4 \t 20 \t 2 \t 46.69% \t 16.04%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.90%\n",
      "  0 \t 20 \t 0 \t 48.46% \t 48.18%\n",
      "  20 \t 20 \t 0 \t 48.48% \t 48.15%\n",
      "  20 \t 0 \t 20 \t 48.19% \t 46.76%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.88%\n",
      "  20 \t 20 \t 0 \t 49.36% \t 15.57%\n",
      "  0 \t 20 \t 0 \t 48.73% \t 47.88%\n",
      "  20 \t 20 \t 0 \t 53.85% \t 19.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 \t 20 \t 0 \t 48.37% \t 48.26%\n",
      "  20 \t 0 \t 20 \t 48.10% \t 46.44%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.15%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 47.96%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 47.60%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.07%\n",
      "  4 \t 20 \t 2 \t 46.85% \t 15.90%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.94%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.67%\n",
      "  20 \t 20 \t 0 \t 55.10% \t 21.80%\n",
      "  20 \t 20 \t 0 \t 53.18% \t 18.92%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.91%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  12 \t 20 \t 2 \t 43.07% \t 19.01%\n",
      "  0 \t 20 \t 2 \t 45.81% \t 16.71%\n",
      "  4 \t 20 \t 2 \t 46.53% \t 16.17%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 20 \t 2 \t 45.11% \t 17.31%\n",
      "  0 \t 20 \t 0 \t 48.66% \t 47.96%\n",
      "  20 \t 20 \t 0 \t 53.77% \t 19.65%\n",
      "  0 \t 20 \t 0 \t 48.75% \t 47.85%\n",
      "  20 \t 20 \t 0 \t 53.20% \t 18.93%\n",
      "  2 \t 20 \t 2 \t 44.19% \t 18.10%\n",
      "  20 \t 20 \t 0 \t 53.17% \t 18.91%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.88%\n",
      "  20 \t 20 \t 2 \t 44.47% \t 17.86%\n",
      "  20 \t 20 \t 0 \t 53.09% \t 18.81%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  7 \t 20 \t 2 \t 44.09% \t 18.18%\n",
      "  0 \t 20 \t 2 \t 46.24% \t 16.34%\n",
      "  2 \t 20 \t 2 \t 44.34% \t 17.98%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  0 \t 20 \t 2 \t 46.96% \t 15.84%\n",
      "  20 \t 20 \t 0 \t 54.35% \t 20.52%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.14% \t 18.87%\n",
      "  20 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 20 \t 0 \t 48.67% \t 47.95%\n",
      "  0 \t 20 \t 0 \t 48.57% \t 48.06%\n",
      "  20 \t 0 \t 20 \t 47.75% \t 45.56%\n",
      "  20 \t 20 \t 0 \t 48.52% \t 48.09%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.83%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.32% \t 19.07%\n",
      "  2 \t 20 \t 2 \t 45.81% \t 16.78%\n",
      "  0 \t 20 \t 0 \t 48.64% \t 47.97%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.86%\n",
      "  20 \t 20 \t 2 \t 44.33% \t 17.98%\n",
      "  20 \t 20 \t 0 \t 49.91% \t 16.02%\n",
      "  0 \t 0 \t 20 \t 48.17% \t 46.68%\n",
      "  4 \t 20 \t 2 \t 42.46% \t 19.50%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.26%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.25%\n",
      "  0 \t 0 \t 20 \t 48.15% \t 46.60%\n",
      "  20 \t 20 \t 2 \t 45.17% \t 17.27%\n",
      "  4 \t 20 \t 2 \t 45.33% \t 17.17%\n",
      "  20 \t 20 \t 2 \t 44.36% \t 17.96%\n",
      "  0 \t 20 \t 0 \t 57.54% \t 26.86%\n",
      "  12 \t 20 \t 2 \t 44.56% \t 17.80%\n",
      "  2 \t 20 \t 2 \t 42.81% \t 19.22%\n",
      "  20 \t 0 \t 20 \t 48.17% \t 46.67%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.97%\n",
      "  0 \t 0 \t 20 \t 48.21% \t 46.83%\n",
      "  0 \t 0 \t 20 \t 48.33% \t 48.24%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.94%\n",
      "  0 \t 20 \t 0 \t 48.45% \t 48.19%\n",
      "  7 \t 20 \t 2 \t 47.43% \t 15.44%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.31%\n",
      "  20 \t 0 \t 20 \t 48.02% \t 46.20%\n",
      "  0 \t 20 \t 2 \t 45.73% \t 16.78%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.69% \t 19.51%\n",
      "  7 \t 20 \t 2 \t 43.08% \t 19.00%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.26%\n",
      "  20 \t 20 \t 2 \t 46.98% \t 15.82%\n",
      "  20 \t 0 \t 20 \t 47.93% \t 45.96%\n",
      "  20 \t 20 \t 2 \t 44.45% \t 17.88%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.28%\n",
      "  0 \t 20 \t 0 \t 53.42% \t 19.24%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.15%\n",
      "  0 \t 20 \t 0 \t 48.60% \t 48.02%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.67%\n",
      "  20 \t 20 \t 0 \t 48.53% \t 48.08%\n",
      "  7 \t 20 \t 2 \t 44.08% \t 18.19%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 20 \t 2 \t 44.25% \t 18.05%\n",
      "  20 \t 20 \t 0 \t 57.53% \t 26.71%\n",
      "  20 \t 20 \t 0 \t 48.68% \t 47.93%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  2 \t 20 \t 0 \t 49.75% \t 15.89%\n",
      "  20 \t 0 \t 20 \t 48.09% \t 46.41%\n",
      "  20 \t 0 \t 20 \t 48.20% \t 46.81%\n",
      "  20 \t 20 \t 0 \t 53.81% \t 19.71%\n",
      "  0 \t 20 \t 0 \t 48.59% \t 48.04%\n",
      "  0 \t 0 \t 20 \t 48.17% \t 46.68%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 47.56%\n",
      "  0 \t 20 \t 0 \t 53.15% \t 18.88%\n",
      "  7 \t 20 \t 2 \t 44.87% \t 17.55%\n",
      "  0 \t 20 \t 0 \t 57.55% \t 26.96%\n",
      "  20 \t 20 \t 0 \t 53.18% \t 18.92%\n",
      "  0 \t 0 \t 20 \t 48.21% \t 46.85%\n",
      "  20 \t 20 \t 2 \t 44.19% \t 18.10%\n",
      "  20 \t 20 \t 0 \t 53.46% \t 19.24%\n",
      "  2 \t 20 \t 2 \t 44.26% \t 18.05%\n",
      "  1 \t 20 \t 2 \t 43.75% \t 18.46%\n",
      "  20 \t 20 \t 0 \t 48.69% \t 47.91%\n",
      "  0 \t 0 \t 20 \t 48.19% \t 46.76%\n",
      "  7 \t 20 \t 2 \t 45.85% \t 16.74%\n",
      "  20 \t 20 \t 0 \t 53.33% \t 19.12%\n",
      "  20 \t 0 \t 20 \t 47.91% \t 45.91%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  2 \t 20 \t 2 \t 44.45% \t 17.89%\n",
      "  0 \t 20 \t 0 \t 57.54% \t 26.81%\n",
      "  20 \t 20 \t 0 \t 54.12% \t 20.18%\n",
      "  20 \t 20 \t 0 \t 53.23% \t 18.98%\n",
      "  20 \t 20 \t 0 \t 53.79% \t 19.71%\n",
      "  20 \t 20 \t 0 \t 57.61% \t 27.96%\n",
      "  20 \t 20 \t 0 \t 53.22% \t 18.98%\n",
      "  20 \t 20 \t 0 \t 50.11% \t 16.20%\n",
      "  20 \t 20 \t 0 \t 54.47% \t 20.52%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.27%\n",
      "  0 \t 20 \t 0 \t 48.78% \t 47.83%\n",
      "  0 \t 20 \t 0 \t 48.32% \t 48.32%\n",
      "  2 \t 20 \t 2 \t 44.11% \t 18.17%\n",
      "  20 \t 20 \t 2 \t 47.31% \t 15.54%\n",
      "  1 \t 20 \t 2 \t 44.24% \t 18.06%\n",
      "  20 \t 0 \t 20 \t 47.92% \t 45.93%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.28%\n",
      "  20 \t 20 \t 0 \t 53.99% \t 19.88%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  13 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 2 \t 44.22% \t 18.07%\n",
      "  20 \t 0 \t 20 \t 48.18% \t 46.72%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.89%\n",
      "  20 \t 20 \t 0 \t 48.43% \t 48.19%\n",
      "  20 \t 20 \t 0 \t 53.19% \t 18.94%\n",
      "  7 \t 20 \t 2 \t 43.46% \t 18.69%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.99%\n",
      "  20 \t 20 \t 0 \t 53.95% \t 19.88%\n",
      "  2 \t 20 \t 2 \t 44.10% \t 18.18%\n",
      "  0 \t 0 \t 20 \t 48.21% \t 46.84%\n",
      "  20 \t 20 \t 0 \t 53.15% \t 18.89%\n",
      "  20 \t 20 \t 0 \t 53.30% \t 19.05%\n",
      "  20 \t 20 \t 0 \t 53.11% \t 18.84%\n",
      "  20 \t 0 \t 20 \t 48.19% \t 46.76%\n",
      "  20 \t 20 \t 0 \t 53.09% \t 18.82%\n",
      "  20 \t 20 \t 0 \t 50.01% \t 16.10%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.88%\n",
      "  20 \t 20 \t 0 \t 48.68% \t 47.92%\n",
      "  20 \t 20 \t 0 \t 53.59% \t 19.45%\n",
      "  4 \t 20 \t 2 \t 45.15% \t 17.32%\n",
      "  0 \t 0 \t 20 \t 48.01% \t 46.17%\n",
      "  13 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 20 \t 0 \t 48.61% \t 48.00%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.69%\n",
      "  0 \t 0 \t 20 \t 48.21% \t 46.85%\n",
      "  2 \t 20 \t 2 \t 44.13% \t 18.16%\n",
      "  20 \t 20 \t 0 \t 53.24% \t 18.99%\n",
      "  20 \t 20 \t 0 \t 48.68% \t 47.92%\n",
      "  4 \t 20 \t 2 \t 46.21% \t 16.43%\n",
      "  2 \t 20 \t 2 \t 44.18% \t 18.11%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.38% \t 19.18%\n",
      "  20 \t 20 \t 0 \t 53.19% \t 18.92%\n",
      "  0 \t 20 \t 0 \t 48.78% \t 47.82%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.83%\n",
      "  20 \t 20 \t 0 \t 53.16% \t 18.91%\n",
      "  20 \t 20 \t 2 \t 44.70% \t 17.67%\n",
      "  0 \t 20 \t 0 \t 53.26% \t 19.03%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  20 \t 20 \t 0 \t 57.56% \t 27.07%\n",
      "  20 \t 20 \t 0 \t 53.22% \t 18.96%\n",
      "  2 \t 20 \t 2 \t 44.09% \t 18.19%\n",
      "  20 \t 0 \t 20 \t 48.14% \t 46.58%\n",
      "  20 \t 20 \t 0 \t 48.53% \t 48.09%\n",
      "  20 \t 20 \t 2 \t 44.32% \t 17.99%\n",
      "  20 \t 20 \t 0 \t 48.57% \t 48.04%\n",
      "  20 \t 0 \t 20 \t 48.07% \t 46.36%\n",
      "  20 \t 20 \t 0 \t 53.84% \t 19.78%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.86%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  4 \t 20 \t 2 \t 45.75% \t 16.81%\n",
      "  4 \t 20 \t 2 \t 42.46% \t 19.50%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  20 \t 20 \t 2 \t 44.15% \t 18.13%\n",
      "  20 \t 20 \t 0 \t 53.09% \t 18.82%\n",
      "  0 \t 20 \t 0 \t 48.65% \t 47.96%\n",
      "  2 \t 20 \t 2 \t 45.86% \t 16.73%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.88%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.89%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  20 \t 20 \t 2 \t 45.02% \t 17.39%\n",
      "  0 \t 20 \t 2 \t 46.04% \t 16.51%\n",
      "  0 \t 20 \t 2 \t 46.70% \t 15.93%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.31%\n",
      "  20 \t 20 \t 2 \t 44.21% \t 18.08%\n",
      "  20 \t 20 \t 0 \t 57.55% \t 26.91%\n",
      "  0 \t 20 \t 0 \t 48.68% \t 47.94%\n",
      "  20 \t 20 \t 0 \t 53.28% \t 19.03%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.28%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.97%\n",
      "  0 \t 0 \t 20 \t 48.15% \t 46.61%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.89%\n",
      "  0 \t 0 \t 20 \t 48.34% \t 47.98%\n",
      "  0 \t 20 \t 0 \t 48.73% \t 47.88%\n",
      "  2 \t 20 \t 2 \t 44.00% \t 18.26%\n",
      "  22 \t 0 \t 20 \t 48.34% \t 48.03%\n",
      "  20 \t 20 \t 0 \t 54.02% \t 19.93%\n",
      "  20 \t 20 \t 2 \t 44.14% \t 18.14%\n",
      "  0 \t 20 \t 0 \t 48.76% \t 47.84%\n",
      "  0 \t 20 \t 0 \t 48.77% \t 47.83%\n",
      "  2 \t 20 \t 2 \t 44.22% \t 18.08%\n",
      "  20 \t 20 \t 0 \t 53.34% \t 19.13%\n",
      "  20 \t 20 \t 0 \t 53.12% \t 18.85%\n",
      "  2 \t 20 \t 2 \t 44.01% \t 18.26%\n",
      "  20 \t 20 \t 0 \t 53.13% \t 18.88%\n",
      "  0 \t 20 \t 0 \t 48.72% \t 47.88%\n",
      "  0 \t 20 \t 0 \t 48.38% \t 48.26%\n",
      "  20 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  0 \t 20 \t 0 \t 53.13% \t 18.86%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 20 \t 0 \t 48.74% \t 47.87%\n",
      "  0 \t 20 \t 0 \t 48.73% \t 47.88%\n",
      "  20 \t 20 \t 0 \t 48.36% \t 48.26%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  7 \t 20 \t 2 \t 43.25% \t 18.86%\n",
      "  20 \t 20 \t 0 \t 53.44% \t 19.22%\n",
      "  4 \t 20 \t 2 \t 44.66% \t 17.71%\n",
      "  0 \t 20 \t 0 \t 48.40% \t 48.24%\n",
      "  20 \t 20 \t 2 \t 44.25% \t 18.04%\n",
      "  0 \t 20 \t 0 \t 48.71% \t 47.90%\n",
      "  20 \t 20 \t 2 \t 44.27% \t 18.03%\n",
      "  7 \t 20 \t 2 \t 44.19% \t 18.10%\n",
      "  20 \t 20 \t 0 \t 53.52% \t 19.36%\n",
      "  7 \t 20 \t 2 \t 43.07% \t 19.01%\n",
      "  4 \t 20 \t 2 \t 45.41% \t 17.10%\n",
      "  20 \t 20 \t 0 \t 54.56% \t 20.67%\n",
      "  20 \t 20 \t 0 \t 49.35% \t 15.57%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.08% \t 18.81%\n",
      "  20 \t 20 \t 2 \t 44.73% \t 17.64%\n",
      "  20 \t 20 \t 0 \t 53.63% \t 19.44%\n",
      "  7 \t 20 \t 2 \t 43.48% \t 18.68%\n",
      "  22 \t 0 \t 20 \t 48.34% \t 47.91%\n",
      "  20 \t 0 \t 20 \t 48.19% \t 46.76%\n",
      "  20 \t 20 \t 0 \t 53.71% \t 19.54%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.30%\n",
      "  2 \t 20 \t 2 \t 44.15% \t 18.14%\n",
      "  0 \t 0 \t 20 \t 48.16% \t 46.66%\n",
      "  0 \t 20 \t 2 \t 45.65% \t 16.85%\n",
      "  7 \t 20 \t 2 \t 44.12% \t 18.16%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.16%\n",
      "  20 \t 20 \t 0 \t 53.94% \t 19.92%\n",
      "  2 \t 20 \t 2 \t 43.23% \t 18.88%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.90%\n",
      "  0 \t 20 \t 0 \t 53.14% \t 18.87%\n",
      "  0 \t 20 \t 0 \t 48.67% \t 47.94%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.83%\n",
      "  20 \t 20 \t 2 \t 44.20% \t 18.09%\n",
      "  2 \t 20 \t 2 \t 42.81% \t 19.22%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.29%\n",
      "  4 \t 20 \t 2 \t 46.09% \t 16.54%\n",
      "  20 \t 20 \t 0 \t 53.21% \t 18.97%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.96%\n",
      "  7 \t 20 \t 2 \t 44.85% \t 17.57%\n",
      "  20 \t 20 \t 0 \t 53.12% \t 18.86%\n",
      "  2 \t 20 \t 2 \t 44.48% \t 17.86%\n",
      "  20 \t 20 \t 2 \t 44.39% \t 17.93%\n",
      "  20 \t 20 \t 0 \t 53.23% \t 18.97%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.68%\n",
      "  20 \t 20 \t 0 \t 53.29% \t 19.04%\n",
      "  20 \t 20 \t 0 \t 53.19% \t 18.93%\n",
      "  20 \t 20 \t 0 \t 53.11% \t 18.84%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.64%\n",
      "  20 \t 20 \t 0 \t 53.81% \t 19.75%\n",
      "  4 \t 20 \t 2 \t 47.29% \t 15.40%\n",
      "  20 \t 20 \t 0 \t 53.51% \t 19.30%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.29%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.63%\n",
      "  2 \t 20 \t 2 \t 44.23% \t 18.07%\n",
      "  0 \t 20 \t 0 \t 48.50% \t 48.14%\n",
      "  0 \t 20 \t 0 \t 55.00% \t 21.61%\n",
      "  0 \t 20 \t 0 \t 48.71% \t 47.91%\n",
      "  20 \t 20 \t 0 \t 53.14% \t 18.89%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  4 \t 20 \t 2 \t 45.65% \t 16.90%\n",
      "  22 \t 0 \t 20 \t 48.34% \t 48.11%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.91%\n",
      "  4 \t 20 \t 2 \t 44.70% \t 17.69%\n",
      "  20 \t 0 \t 20 \t 48.07% \t 46.35%\n",
      "  0 \t 0 \t 20 \t 48.19% \t 46.75%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  22 \t 0 \t 20 \t 48.34% \t 47.80%\n",
      "  0 \t 0 \t 20 \t 48.33% \t 48.23%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  0 \t 20 \t 0 \t 48.71% \t 47.90%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.90%\n",
      "  20 \t 0 \t 20 \t 48.14% \t 46.56%\n",
      "  20 \t 20 \t 0 \t 53.14% \t 18.88%\n",
      "  22 \t 0 \t 20 \t 48.34% \t 47.94%\n",
      "  20 \t 20 \t 0 \t 53.16% \t 18.90%\n",
      "  20 \t 20 \t 0 \t 53.97% \t 19.96%\n",
      "  20 \t 20 \t 0 \t 49.33% \t 15.55%\n",
      "  0 \t 0 \t 20 \t 48.33% \t 48.23%\n",
      "  0 \t 20 \t 0 \t 48.32% \t 48.32%\n",
      "  7 \t 20 \t 2 \t 44.23% \t 18.07%\n",
      "  20 \t 20 \t 0 \t 48.71% \t 47.89%\n",
      "  20 \t 20 \t 0 \t 54.64% \t 20.98%\n",
      "  20 \t 20 \t 2 \t 44.15% \t 18.14%\n",
      "  20 \t 20 \t 0 \t 53.37% \t 19.13%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  0 \t 0 \t 20 \t 48.22% \t 46.89%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.66%\n",
      "  20 \t 20 \t 0 \t 53.99% \t 20.00%\n",
      "  0 \t 0 \t 20 \t 48.12% \t 46.52%\n",
      "  20 \t 20 \t 0 \t 57.56% \t 27.05%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.10%\n",
      "  20 \t 20 \t 0 \t 53.14% \t 18.87%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.20%\n",
      "  4 \t 20 \t 2 \t 46.57% \t 16.04%\n",
      "  4 \t 20 \t 2 \t 45.01% \t 17.43%\n",
      "  17 \t 20 \t 2 \t 42.46% \t 19.50%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.26%\n",
      "  20 \t 20 \t 0 \t 53.61% \t 19.47%\n",
      "  4 \t 20 \t 2 \t 44.74% \t 17.65%\n",
      "  0 \t 0 \t 20 \t 48.23% \t 46.93%\n",
      "  20 \t 20 \t 0 \t 53.58% \t 19.38%\n",
      "  20 \t 0 \t 20 \t 48.33% \t 48.19%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.26%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.98%\n",
      "  20 \t 0 \t 20 \t 48.08% \t 46.38%\n",
      "  20 \t 20 \t 2 \t 44.43% \t 17.90%\n",
      "  20 \t 20 \t 0 \t 53.72% \t 19.59%\n",
      "  0 \t 20 \t 0 \t 48.78% \t 47.82%\n",
      "  0 \t 0 \t 20 \t 48.33% \t 48.14%\n",
      "  20 \t 20 \t 2 \t 44.93% \t 17.47%\n",
      "  20 \t 0 \t 20 \t 48.21% \t 46.85%\n",
      "  20 \t 20 \t 0 \t 53.49% \t 19.32%\n",
      "  20 \t 0 \t 20 \t 48.32% \t 48.27%\n",
      "  0 \t 20 \t 0 \t 48.34% \t 48.32%\n",
      "  20 \t 20 \t 0 \t 55.05% \t 21.71%\n",
      "  20 \t 0 \t 20 \t 48.23% \t 46.92%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.67%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.97%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 20 \t 2 \t 44.41% \t 17.91%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 20 \t 0 \t 48.75% \t 47.85%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  0 \t 0 \t 20 \t 48.19% \t 46.75%\n",
      "  4 \t 20 \t 2 \t 44.95% \t 17.48%\n",
      "  0 \t 20 \t 0 \t 48.54% \t 48.08%\n",
      "  0 \t 20 \t 0 \t 48.70% \t 47.91%\n",
      "  20 \t 20 \t 2 \t 44.18% \t 18.11%\n",
      "  20 \t 0 \t 20 \t 48.34% \t 48.09%\n",
      "  20 \t 20 \t 0 \t 54.87% \t 21.12%\n",
      "  0 \t 20 \t 0 \t 48.52% \t 48.11%\n",
      "  20 \t 0 \t 20 \t 48.17% \t 46.70%\n",
      "  20 \t 20 \t 2 \t 44.00% \t 18.26%\n",
      "  20 \t 20 \t 0 \t 53.20% \t 18.96%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20 \t 20 \t 0 \t 54.06% \t 19.98%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 0 \t 53.17% \t 18.91%\n",
      "  20 \t 0 \t 20 \t 48.20% \t 46.80%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.28%\n",
      "  2 \t 20 \t 2 \t 44.13% \t 18.15%\n",
      "  4 \t 20 \t 2 \t 45.08% \t 17.37%\n",
      "  20 \t 20 \t 0 \t 54.28% \t 20.28%\n",
      "  2 \t 20 \t 2 \t 44.18% \t 18.11%\n",
      "  20 \t 20 \t 0 \t 48.67% \t 47.94%\n",
      "  20 \t 20 \t 2 \t 44.30% \t 18.00%\n",
      "  0 \t 20 \t 0 \t 57.52% \t 26.62%\n",
      "  2 \t 20 \t 2 \t 44.01% \t 18.26%\n",
      "  0 \t 20 \t 0 \t 48.33% \t 48.32%\n",
      "  0 \t 0 \t 20 \t 48.32% \t 48.31%\n",
      "  20 \t 20 \t 0 \t 53.12% \t 18.85%\n",
      "  0 \t 20 \t 0 \t 48.40% \t 48.25%\n",
      "  0 \t 20 \t 0 \t 48.76% \t 47.85%\n",
      "  20 \t 20 \t 0 \t 49.95% \t 16.06%\n",
      "  0 \t 20 \t 0 \t 53.18% \t 18.93%\n",
      "  0 \t 20 \t 0 \t 48.76% \t 47.84%\n",
      "  7 \t 20 \t 2 \t 45.92% \t 16.69%\n",
      "  20 \t 20 \t 0 \t 54.93% \t 21.22%\n",
      "  4 \t 20 \t 2 \t 44.63% \t 17.75%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  20 \t 20 \t 2 \t 44.63% \t 17.73%\n",
      "  20 \t 0 \t 20 \t 48.22% \t 46.87%\n",
      "  20 \t 20 \t 2 \t 44.34% \t 17.97%\n",
      "  22 \t 22 \t 13 \t 84.80% \t 8.95%\n",
      "  0 \t 0 \t 20 \t 48.24% \t 46.95%\n",
      "  20 \t 20 \t 2 \t 46.97% \t 15.83%\n",
      "  4 \t 20 \t 2 \t 44.84% \t 17.58%\n",
      "  20 \t 20 \t 0 \t 48.66% \t 47.95%\n",
      "  20 \t 20 \t 0 \t 53.88% \t 19.75%\n",
      "  20 \t 20 \t 0 \t 53.09% \t 18.81%\n"
     ]
    }
   ],
   "source": [
    "# Print prediction, result, and how certain the result is\n",
    "best = np.argsort(predictions)\n",
    "print(' Best  Guess1  Guess2  Certainty1      Certainty2')\n",
    "for i in range(test_size):\n",
    "    print(' ', test_labels[i], '\\t', best[i][-1], '\\t', best[i][-2], '\\t', \\\n",
    "          \"{:.2%}\".format(predictions[i][best[i][-1]]), '\\t', \"{:.2%}\".format(predictions[i][best[i][-2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of guesses until correct choice: [357 256  40   8  29   4   8   0   0   0   0   1   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "Cumilative chance that the choice was correct by: [0.508 0.872 0.929 0.94  0.982]\n",
      "The count of most occuring tests: [333 220  42  33  32  28   8   4   2   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0]\n",
      "Cumilative chance that the choice was correct by: [0.474 0.787 0.846 0.893 0.939]\n"
     ]
    }
   ],
   "source": [
    "# Print general statistics about in how many guesses the AI would be correct\n",
    "correct = np.zeros(best.shape[1])\n",
    "most_occuring = np.sort(np.bincount(test_labels))[::-1]\n",
    "for i in range(test_size):\n",
    "    for j in range(correct.size):\n",
    "        if best[i][-j-1] == test_labels[i]:\n",
    "            correct[j] = correct[j] + 1\n",
    "            break\n",
    "np.set_printoptions(precision=3)\n",
    "print('The count of guesses until correct choice:', correct.astype(int))\n",
    "print('Cumilative chance that the choice was correct by:', \\\n",
    "      np.apply_along_axis(lambda x: x / test_size, 0, np.cumsum(correct))[0:5])\n",
    "print('The count of most occuring tests:', most_occuring)\n",
    "print('Cumilative chance that the choice was correct by:', \\\n",
    "      np.apply_along_axis(lambda x: x / test_size, 0, np.cumsum(most_occuring))[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.     2.578  4.406  5.26   5.638  5.916  7.789  8.758 11.277 15.075\n",
      " 15.372 15.449 20.166 20.265 20.404 20.747 26.301 29.122 30.071 38.377\n",
      " 39.047 41.726 41.981]\n",
      "[ 1.     1.414  2.818  3.115  3.554  5.004  5.472  5.536  5.59   6.23\n",
      "  6.912  8.48   8.691  9.654  9.97  12.202 12.32  14.212 15.444 21.156\n",
      " 22.543 24.691 38.048]\n",
      "[ 1.     1.101  1.83   1.873  2.461  2.908  3.708  3.71   3.739  4.221\n",
      "  4.82   4.83   7.33   7.486  8.574  9.997 10.109 11.325 15.863 19.491\n",
      " 20.405 24.777 41.972]\n",
      "The average: [ 1.     1.435  2.41   3.08   3.687  4.098  4.695  5.136  5.71   6.347\n",
      "  7.047  7.625  8.293  9.144 10.107 11.193 13.002 15.33  17.725 21.235\n",
      " 25.066 30.43  41.326]\n",
      "30 second best results from 878 are within 1 percent speed difference\n",
      "34 non best results from 878 are within 1 percent speed difference\n",
      "100 second best results from 878 are within 5 percent speed difference\n"
     ]
    }
   ],
   "source": [
    "# Display relative timing of all experiments, and print the ones which are relatively close\n",
    "timings = np.apply_along_axis(lambda x: np.sort(x), 1, arr[:, parameter_count:])\n",
    "for i in range(timings.shape[0]):\n",
    "    fastest = timings[i][0]\n",
    "    for j in range(timings.shape[1]):\n",
    "        timings[i][j] = timings[i][j] / fastest\n",
    "\n",
    "for i in range(3):\n",
    "    print(timings[i])\n",
    "    \n",
    "print('The average:', np.average(timings, 0))\n",
    "\n",
    "count = 0\n",
    "for i in range(timings.shape[0]):\n",
    "    if timings[i][1] < 1.01:\n",
    "        count = count + 1\n",
    "print(count, 'second best results from', timings.shape[0], 'are within 1 percent speed difference')\n",
    "\n",
    "count = 0\n",
    "for i in range(timings.shape[0]):\n",
    "    for j in range(1, timings.shape[1]):\n",
    "        if timings[i][j] < 1.01:\n",
    "            count = count + 1\n",
    "print(count, 'non best results from', timings.shape[0], 'are within 1 percent speed difference')\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(timings.shape[0]):\n",
    "    if timings[i][1] < 1.05:\n",
    "        count = count + 1\n",
    "print(count, 'second best results from', timings.shape[0], 'are within 5 percent speed difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365 first guesses from 703 are within 1 percent speed difference\n",
      "381 first guesses from 703 are within 5 percent speed difference\n",
      "615 of first two guesses from 703 are within 1 percent speed difference\n"
     ]
    }
   ],
   "source": [
    "# Count the first guesses that were relatively quick\n",
    "test_timings = data[:test_size,parameter_count:]\n",
    "for i in range(test_timings.shape[0]):\n",
    "    fastest = np.min(test_timings[i])\n",
    "    for j in range(test_timings.shape[1]):\n",
    "        test_timings[i][j] = test_timings[i][j] / fastest\n",
    "        \n",
    "count = 0\n",
    "for i in range(test_size):\n",
    "    if test_timings[i][best[i][-1]] < 1.01:\n",
    "        count = count + 1\n",
    "print(count, 'first guesses from', test_size, 'are within 1 percent speed difference')\n",
    "\n",
    "count = 0\n",
    "for i in range(test_size):\n",
    "    if test_timings[i][best[i][-1]] < 1.05:\n",
    "        count = count + 1\n",
    "print(count, 'first guesses from', test_size, 'are within 5 percent speed difference')\n",
    "\n",
    "count = 0\n",
    "for i in range(test_size):\n",
    "    if test_timings[i][best[i][-1]] < 1.01 or test_timings[i][best[i][-2]] < 1.01:\n",
    "        count = count + 1\n",
    "print(count, 'of first two guesses from', test_size, 'are within 1 percent speed difference')\n",
    "\n",
    "for i in r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-27b4c559aede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrankdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TB'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    146\u001b[0m           \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m   \"\"\"\n\u001b[1;32m--> 148\u001b[1;33m   \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m   \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m   \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     50\u001b[0m                       ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
